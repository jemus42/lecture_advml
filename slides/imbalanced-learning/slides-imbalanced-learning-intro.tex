\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

\newcommand{\sens}{\mathbf{A}} % vector x (bold)
\newcommand{\ba}{\mathbf{a}}
\newcommand{\batilde}{\tilde{\mathbf{a}}}
\newcommand{\Px}{\mathbb{P}_{x}} % P_x
\newcommand{\Pxj}{\mathbb{P}_{x_j}} % P_{x_j}
\newcommand{\indep}{\perp \!\!\! \perp} % independence symbol
% ml - ROC
\newcommand{\np}{n_{+}} % no. of positive instances
\newcommand{\nn}{n_{-}} % no. of negative instances
\newcommand{\rn}{\pi_{-}} % proportion negative instances
\newcommand{\rp}{\pi_{+}} % proportion negative instances
% true/false pos/neg:
\newcommand{\tp}{\# \text{TP}} % true pos
\newcommand{\fap}{\# \text{FP}} % false pos (fp taken for partial derivs)
\newcommand{\tn}{\# \text{TN}} % true neg
\newcommand{\fan}{\# \text{FN}} % false neg

\usepackage{multicol}

\newcommand{\titlefigure}{figure_man/imbalanced_data_plot_title}
\newcommand{\learninggoals}{
  \item What are imbalanced data sets
  \item Disadvantage of accuracy on imbalanced data sets
  \item Overview of techniques for handling imbalanced data sets
}

\title{Advanced Machine Learning}
\date{}

\begin{document}

\lecturechapter{Introduction to Imbalanced Learning}
\lecture{Advanced Machine Learning}



\sloppy

\begin{vbframe}{Imbalanced Data Sets}
%
\small{
  \begin{itemize}
%  	
	\begin{minipage}{0.45\textwidth}
%		    
		    \item Class imbalance: the occurrences of the classes are significantly different. 
%		     
		    \item Consequence: undesirable predictive behavior.
	\end{minipage}
	\begin{minipage}{0.45\textwidth}    
		\begin{center}
			%    	
			\includegraphics[width=0.5\textwidth]{figure_man/balanced_data_plot}
			\includegraphics[width=0.5\textwidth]{figure_man/imbalanced_data_plot}
			%    	
		\end{center}
	\end{minipage}

%

  \end{itemize}}
%
\end{vbframe}

\begin{vbframe}{Imbalanced Data Sets: Examples}
    \small
    \begin{table}[h]
        \scriptsize
        \centering
        \begin{tabular}{cccc}
            \toprule
            \textbf{Domain} & \textbf{Task} & \textbf{Majority Class} & \textbf{Minor Class} \\ [5pt]
            \hline
            Medicine & Predict tumor pathology & Benign &  Malignant \\ [5pt]
            Information retrieval & Find relevant items & Irrelevant items & Relevant items \\ [5pt]
            Tracking criminals & Detect fraud emails & Non-fraud emails & Fraud emails \\ [5pt]
            Weather prediction & Predict extreme weather & Normal weather & Tornado, hurricane \\
            \hline
        \end{tabular}
    \end{table}
    
	\begin{itemize}
        \item In binary classification (i.e., $\Yspace =\{-1,+1\}$) the minority class is usually the positive class ($y=+1$), while the majority class is the negative ($y=-1$). 
        \item The positive class is oftentimes the more important one in real-world applications.
        \item Recall that imbalanced data sets can also be a source of bias related to the concept of fairness in ML, e.g.\ more data on white recidivism outcomes than for blacks.
	\end{itemize}

\end{vbframe}

\frame{
\frametitle{Issues with Classical Classifiers}

\begin{itemize}
    \item Ideal case: correctly classify as many instances as possible \\ $\Rightarrow$ High accuracy,	preferably $100\%$.
    \vspace{10pt}
    
	\item We often obtain on imbalanced data sets:
	\begin{itemize}
		\small	
		\item a \textbf{good} accuracy on the \textbf{majority} class(es),		
		\item a \textbf{poor} accuracy on the \textbf{minority} class(es). 	
	\end{itemize}
    \vspace{10pt}

	\item Reason: the classifier is biased towards the \textbf{majority} class(es), as predicting the majority class pays off in terms of accuracy.
    \vspace{10pt}

	\item This problem can be illustrated by means of the \textbf{accuracy paradox}.
    \vspace{10pt}

\end{itemize}
%
}
 

\begin{vbframe}{Accuracy Paradox: Example}
%
	\footnotesize
	\begin{itemize}
		%	
		\item Consider the following setting:
%		

		\begin{minipage}{0.55\textwidth}    
%			
		\begin{itemize}
			\scriptsize
%			
			\item $p(\xv ~| -1) \sim \normal_2\left( 
			\begin{pmatrix}
				0 \\ 0
			\end{pmatrix}  , 
			\begin{pmatrix}
			1  & 0 \\ 0 & 1
			\end{pmatrix}   \right) $
%		 
			\item  $p(\xv ~| ~ +1) \sim \normal_2\left( 
			\begin{pmatrix}
				0 \\ -2
			\end{pmatrix}  , 
			\begin{pmatrix}
				0.1  & 0 \\ 0 & 0.1
			\end{pmatrix}   \right)  $
%		
			\item $n_+ = 25$ and $n_- = 1000$
%		
		\end{itemize}
		\end{minipage}
		\begin{minipage}{0.35\textwidth}    
		\begin{center}
			%    	 
			\includegraphics[width=0.8\textwidth]{figure_man/accuracy_paradox}
			%    	
		\end{center}
		\end{minipage}
%	
	\item We compare two models $f_1(\xv) \equiv -1$ and $f_2(\xv) = 2 \cdot \mathds{1}_{[ \xv \in [-0.66,0.47]\times [-2.74,-1.12] ]} -1.$
%	
	\item $f_1$ has an overall accuracy of $\approx 0.976,$ while $f_2$ has an overall accuracy of $\approx 0.951.$
%	
	\item However, $f_1$ has not a single correct classification for the positive class, i.e., an accuracy of $0$ for the positive class, while $f_2$ classifies \textbf{all} positives correctly, i.e., an accuracy of $1$ for the positive class.
%	
		%
	\end{itemize}
	%	
\end{vbframe} 



\begin{vbframe}{Accuracy Paradox: Consequences}
	%
	\begin{itemize}
		\item Focusing only on the overall accuracy can have serious consequences. 
        \vspace{20pt}
        
        \item Example:
		\begin{itemize}
			\small
			\item Assume that only 0.5\% of the patients have the disease,	
			\item Always predicting ``no disease'' $\leadsto$ accuracy of 99.5\% \\	
			$\leadsto$ Every patient is sent back home!		
		\end{itemize}
        \vspace{20pt}
        
		\item Ideal performance measure: the learning is \emph{properly} biased towards the minority class(es).	
	\end{itemize}
\end{vbframe} 


\begin{vbframe}{Dealing with Imbalanced Data Sets}
\small
\begin{table}[h]
    \centering
    \begin{tabular}{p{0.2\textwidth} p{0.35\textwidth} p{0.35\textwidth}}
        \toprule
        \textbf{Approach} & \textbf{Main idea} & \textbf{Remark} \\ [5pt]
        \hline
        Algorithm-level & Bias classifiers towards minority & Special knowledge about classifiers is needed \\ [5pt]
        \hline
        Data-level & Re-balance the classes by resampling & No modification of classifiers is needed \\ [5pt]
        \hline
        Cost-sensitive Learning & Introduce different costs for misclassification when learning & Between algorithm- and data-level approaches\\ [15pt]
        \hline
        Ensemble-based & Ensemble learning plus one of three techniques above & - \\ [5pt]
        \bottomrule
    \end{tabular}
\end{table}

\end{vbframe}



\endlecture
\end{document}
