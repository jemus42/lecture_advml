\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-multitarget}

\usepackage{multicol}

\newcommand{\titlefigure}{figure/Slide2}
\newcommand{\learninggoals}{
  \item Understand the practical relevance of multi-target prediction problems
  \item Know the relevant special cases of multi-target prediction
  \item Understand the difference between inductive and transductive learning problems
}

\title{Advanced Machine Learning}
\date{}

\begin{document}

\lecturechapter{Multi-Target Prediction: Introduction}
\lecture{Advanced Machine Learning}



\sloppy

\begin{vbframe}{Multi-target prediction: Motivation}
    \begin{itemize}    
        \item Conventional supervised learning: Label space $\Yspace$ is 1-D.	

        \item Multi-target prediction (MTP): multiple targets of mixed types (binary, nominal, ordinal, real-valued).
        
        \item Learn one model per target independently? $\leadsto$ Targets can be \emph{statistically dependent}.

        \item Multi-label Emotions Dataset: 4 emotions of a music piece. Multiple emotions may be attributed to a single piece. Mutual information of the labels are:
        \begin{center}
            \begin{tabular}{lrrrr}
            \toprule
              & \textbf{Calm} & \textbf{Quiet} & \textbf{Sad} & \textbf{Angry}\\
            \midrule
            \textbf{Calm} & 1.000 & 0.073 & 0.018 & \textcolor{red}{\textbf{0.290}}\\
            \textbf{Quiet} & 0.073 & 1.000 & \textcolor{red}{\textbf{0.241}} & \textcolor{red}{\textbf{0.164}}\\
            \textbf{Sad} & 0.018 & \textcolor{red}{\textbf{0.241}} & 1.000 & 0.067\\
            \textbf{Angry} & \textcolor{red}{\textbf{0.290}} & \textcolor{red}{\textbf{0.164}} & 0.067 & 1.000\\
            \bottomrule
        \end{tabular}
        \end{center}
        
		\item It might be better to tackle targets \emph{simultaneously}.
    \end{itemize}

\end{vbframe}

\begin{frame}{Multi-target prediction: Characteristics}

    Characterized by instances $\xv \in \Xspace$ and targets $m \in [1, 2, \ldots, l]$ with following properties: 

    \begin{itemize} \small

        \item A training set $\D = \{(\xi, \yim)\}_{i=1}^n$, where $\yim \in \Yspace_m$ is label for target $m$.  
        
        \item $n$ instances and $l$ targets $\leadsto$ Scores $\yim$ can be arranged in an $n \times l$ matrix $Y$. Note $Y$ may have missing values.

        \item Label space $\Yspace_m$ can be nominal, ordinal or real-valued.  
    
        \item Goal: to predict scores for any pair $(\xv, m) \in \Xspace \times [1, 2, \ldots, l]$.  
    
    \end{itemize}
In conventional MTP setting: no available side information for targets. 
\end{frame}

\section{Special Cases of Multi-target Prediction}

\begin{frame}{Multivariate regression}
    \begin{itemize}
        \item $|\Tspace|=l$ $\leadsto$ all targets are observed during training. 

        \begin{minipage}{0.45\textwidth}    
        
            \item The score set is $\Yspace = \mathbb{R}$. 

            \item No side information is available for targets. We can re-index the targets with $\tv = (1, 2, \ldots, l)^T$. 
        \end{minipage}
        \hfill
        \begin{minipage}{0.45\textwidth}    
            \begin{center} 	
            \includegraphics[width=0.99\textwidth,trim = 0 0 100 100,clip]{figure/Slide1} 	\tiny
            \\ Waegeman et al. (2019), Multi-target prediction:
            A unifying view on problems and methods (\href{https://arxiv.org/pdf/1809.02352.pdf}{\underline{URL}}).

            \end{center}
        \end{minipage}
    \end{itemize}

	Example: Predict whether a protein (rows) will bind to a set of experimentally developed small molecules (columns).
%
\end{frame}



\begin{frame}{Multi-label classification}
	\begin{itemize}

        \begin{minipage}{0.45\textwidth}  
            \item All targets are observed during training.
            
            \item No side information is available for targets. 

			\item The score matrix $Y$ has no missing values. 	

			\item $\Yspace_m = \{0,1\}$ for all $m$.	
		\end{minipage}
        \hfill
		\begin{minipage}{0.45\textwidth}    
		\begin{center}
			\includegraphics[width=0.9\textwidth,trim = 0 0 100 100,clip]{figure/Slide2} \tiny
			\\ Waegeman et al. (2019), Multi-target prediction:
			A unifying view on problems and methods (\href{https://arxiv.org/pdf/1809.02352.pdf}{\underline{URL}}).
		\end{center}
		\end{minipage}
	\end{itemize}	

	Example: Assign for documents (rows) the appropriate category tags (columns).

\end{frame}


\begin{frame}{Label ranking}
    In \emph{label ranking}, each instance is associated with a ranking of targets. 

		\begin{itemize}
			
			\begin{minipage}{0.45\textwidth}    
                \item All targets are observed during training. 

    			\item No side information is available for targets. 		
                
    			\item $Y$ has no missing values. 
                
    			\item $\Yspace_m = \{1, \ldots , l\}$ for all $m$, and the scores (i.e. ranks) $\yim \neq y_{k}^{(i)}$ for all $1 \leq m,k \neq l$. 
			\end{minipage}
            \hfill
			\begin{minipage}{0.45\textwidth}    
    			\begin{center}
                    \includegraphics[width=0.9\textwidth,trim = 0 0 100 0,clip]{figure/labelranking} \tiny
    				\\ Waegeman et al. (2019), Multi-target prediction:
    				A unifying view on problems and methods (\href{https://arxiv.org/pdf/1809.02352.pdf}{\underline{URL}}).
     	
    			\end{center}
	        \end{minipage}
		\end{itemize}
  
	Example: Predict for users (rows) their preferences over specific activities (columns).
	
\end{frame}


\begin{frame}{Multi-task learning}

		\begin{itemize}
			
			\begin{minipage}{0.45\textwidth}  

                \item \textbf{Not all targets are relavent for all instances}. E.g. a student may only attend one school, other labels are \textbf{irrelavent}.
                
                \item All targets are observed during training.

			    \item No side information is available for targets. 
       
				\item Label space is homogenous across columns of $Y$, e.g., $\Yspace_m = \{0,1\}$ or $\Yspace_m = \R$ for all $m$.

			\end{minipage}
            \hfill
			\begin{minipage}{0.45\textwidth}    
				\begin{center} 	
					\includegraphics[width=0.99\textwidth,trim = 0 0 100 100,clip]{figure/Slide3} \tiny
					\\ Waegeman et al. (2019), Multi-target prediction:
					A unifying view on problems and methods (\href{https://arxiv.org/pdf/1809.02352.pdf}{\underline{URL}}).	
				\end{center}
			\end{minipage}
		\end{itemize}
	Example: Predict for students (rows) the final grades for a specific high-school course (columns).


\end{frame}

\begin{frame}{Remarks}

		\begin{itemize}
            \item It is also possible when the $m$-th task is multiclass classification. That is, $f(\xv)_m \in \R^{g_m}$ is the probability predictions for $g_m$ classes. \\
            $\leadsto$ The techniques for multi-target learning are also applicalble under this setting. But the notations will be cumbersome, so we will not cover it.

            \item Label space can be inhomogeneous. E.g. $\Yspace_m = \{0, 1\}$ and $\Yspace_k = \R$. \\
            $\leadsto$ A mixture of multi-label classification and multivariate regression.
            
		\end{itemize}

\end{frame}


\section{Learning with Side Information on Targets}


\begin{vbframe}{Side information on targets}
    \begin{itemize}
        \item In some applications additional side information about targets is available.
        \item Examples: 
        \begin{itemize}
            \begin{minipage}{0.45\textwidth}    
                \item Extra representation for the target molecules in drug design application (\emph{structured representation}).
            \end{minipage}
            \hfill
            \begin{minipage}{0.4\textwidth}    
                \begin{center}
                    \includegraphics[width=0.9\textwidth,trim = 0 0 50 80,clip]{figure/Slide4}	
                \end{center}
            \end{minipage}
            
            \begin{minipage}{0.45\textwidth}   
                \item Taxonomy on document categories (\emph{hierarchy}).
            \end{minipage}
            \hfill
            \begin{minipage}{0.4\textwidth}    
                \begin{center}  	
                    \includegraphics[width=0.9\textwidth,trim = 0 0 100 20,clip]{figure/Slide5}	
                \end{center}
            \end{minipage}
            
            \begin{minipage}{0.45\textwidth}    
                \item Information about schools (geographical location, school reputation) in student mark forecasting (\emph{feature representation}).
            \end{minipage}
            \hfill
            \begin{minipage}{0.4\textwidth}    
                \begin{center}	                                     
                    \includegraphics[width=0.9\textwidth,trim = 0 0 100 20,clip]{figure/Slide6} \tiny
                    \\ Waegeman et al. (2019), Multi-target prediction: A unifying view on problems and methods (\href{https://arxiv.org/pdf/1809.02352.pdf}{\underline{URL}}).	
                \end{center}
            \end{minipage}
        \end{itemize}
        
        \item Such problems are referred to as dyadic or link  prediction.
        
        \item Such problems fulfill the four properties of MTP setting.
        
        \item Scores $\yim$ can be arranged in a matrix $Y$, which is often sparse. 
        
        \item Thus, \emph{dyadic prediction} can be seen as \emph{multi-target prediction with target features}. 
    \end{itemize}
\end{vbframe}


\begin{frame}{Inductive vs.\ Transductive Learning}
	\begin{itemize} 
		\item In previous problems, 
		\begin{enumerate}
			\item predictions need be be generated for novel instances, 
			\item targets are known beforehand and observed during training.
		\end{enumerate}
		\item These problems are \emph{inductive} w.r.t.\ instances and \emph{transductive} w.r.t.\ targets.

		\begin{minipage}{0.45\textwidth}    
			\item Side information is important for generalizing to novel targets.
            \begin{itemize}
                \item a novel target molecule in the drug design,
                \item a novel tag in the document annotation,
            \end{itemize} 
		\end{minipage}
        \hfill
		\begin{minipage}{0.45\textwidth}    
			\begin{center}
			
				\tiny{$$\qquad g(.,.): \mbox{target similarity}$$}
				\includegraphics[width=0.9\textwidth,trim = 0 0 0 50,clip]{figure/Slide7}  \tiny
				\\ Waegeman et al. (2019), Multi-target prediction:
				A unifying view on problems and methods (\href{https://arxiv.org/pdf/1809.02352.pdf}{\underline{URL}}).
	
			\end{center}
		\end{minipage}
	\end{itemize}
\end{frame}

\begin{frame}{Subdivision of different learning settings}

	\begin{itemize}
		\item Setting A --- transductive w.r.t. targets and instances. Goal: predict missing values of score matrix (\emph{matrix completion}).

		\item Setting B --- transductive w.r.t.\ targets and inductive w.r.t. instances.

	\end{itemize}

	\begin{minipage}{0.55\textwidth}
		\begin{itemize}
			\item Setting C --- inductive w.r.t.\ targets and transductive w.r.t. instances. $\leadsto$ Some targets are unobserved during training but may appear at prediction time.

			\item Setting D --- inductive w.r.t.\ both targets and instances (\emph{zero-shot learning}).
            
		\end{itemize}
	\end{minipage}
    \hfill
	\begin{minipage}{0.4\textwidth}
	   \center
	   \includegraphics[width=0.99\textwidth,trim = 0 0 50 0,clip]{figure/Slide16}  \tiny
	   \\ Waegeman et al. (2019), Multi-target prediction: A unifying view on problems and methods (\href{https://arxiv.org/pdf/1809.02352.pdf}{\underline{URL}}).
	\end{minipage}
\end{frame}



%
\endlecture
\end{document}
